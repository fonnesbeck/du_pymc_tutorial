<!DOCTYPE html>
<html lang="en"><head>
<script src="slides_files/libs/clipboard/clipboard.min.js"></script>
<script src="slides_files/libs/quarto-html/tabby.min.js"></script>
<script src="slides_files/libs/quarto-html/popper.min.js"></script>
<script src="slides_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="slides_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="slides_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="slides_files/libs/quarto-html/quarto-syntax-highlighting-dark-0348920b7671f696dc9078d39bff215e.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.32">

  <meta name="author" content="Christopher Fonnesbeck PyMC Labs">
  <title>Getting Started with PyMC v5</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="slides_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="slides_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
      }
    pre.numberSource { margin-left: 3em;  padding-left: 4px; }
    div.sourceCode
      { color: #e1e4e8; background-color: #24292e; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #e1e4e8; } /* Normal */
    code span.al { color: #ff5555; font-weight: bold; } /* Alert */
    code span.an { color: #6a737d; } /* Annotation */
    code span.at { color: #f97583; } /* Attribute */
    code span.bn { color: #79b8ff; } /* BaseN */
    code span.bu { color: #f97583; } /* BuiltIn */
    code span.cf { color: #f97583; } /* ControlFlow */
    code span.ch { color: #9ecbff; } /* Char */
    code span.cn { color: #79b8ff; } /* Constant */
    code span.co { color: #6a737d; } /* Comment */
    code span.cv { color: #6a737d; } /* CommentVar */
    code span.do { color: #6a737d; } /* Documentation */
    code span.dt { color: #f97583; } /* DataType */
    code span.dv { color: #79b8ff; } /* DecVal */
    code span.er { color: #ff5555; text-decoration: underline; } /* Error */
    code span.ex { color: #f97583; font-weight: bold; } /* Extension */
    code span.fl { color: #79b8ff; } /* Float */
    code span.fu { color: #b392f0; } /* Function */
    code span.im { color: #9ecbff; } /* Import */
    code span.in { color: #6a737d; } /* Information */
    code span.kw { color: #f97583; } /* Keyword */
    code span.op { color: #e1e4e8; } /* Operator */
    code span.ot { color: #b392f0; } /* Other */
    code span.pp { color: #f97583; } /* Preprocessor */
    code span.re { color: #6a737d; } /* RegionMarker */
    code span.sc { color: #79b8ff; } /* SpecialChar */
    code span.ss { color: #9ecbff; } /* SpecialString */
    code span.st { color: #9ecbff; } /* String */
    code span.va { color: #ffab70; } /* Variable */
    code span.vs { color: #9ecbff; } /* VerbatimString */
    code span.wa { color: #ff5555; } /* Warning */
  </style>
  <link rel="stylesheet" href="slides_files/libs/revealjs/dist/theme/quarto-108d9316e08c8bb7fa8a9109f3f6a9a1.css">
  <link rel="stylesheet" href=".reveal h1, .reveal h2, .reveal h3 {
  line-height: 1.2;
  margin-bottom: 1em;
}
.reveal .slides section {
  text-align: left;
}
.reveal .slides section[data-state=" title-slide"]="" {="" text-align:="" center;="" }="" .reveal="" code="" font-size:="" 0.85em;="" line-height:="" 1.3;="" pre="" 0.75em;="" 1.4;="" max-height:="" 500px;="" overflow-y:="" auto;="" .columns="" display:="" flex;="" align-items:="" flex-start;="" .column="" flex:="" 1;="" margin:="" 0="" 1em;="" img="" max-width:="" 100%;="" 70vh;="" object-fit:="" contain;="" .center="" .fragment="" opacity:="" 0.3;="" .fragment.visible="" }"="">
  <link href="slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="slides_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="slides_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="slides_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="slides_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-dark">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Getting Started with PyMC v5</h1>
  <p class="subtitle">Data Umbrella Tutorial</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Christopher Fonnesbeck<br><span style="font-size: 0.8em; color: #888;">PyMC Labs</span> 
</div>
</div>
</div>

</section>
<section>
<section id="getting-started-with-pymc-v5" class="title-slide slide level1 center">
<h1>Getting Started with PyMC v5</h1>
<div class="center">
<div style="font-size: 4em; margin-bottom: 0.5em; margin-top: 1em;">
<p>üêç + üìä + üß† = PyMC</p>
</div>
<div style="font-size: 1.5em; color: #888; margin-bottom: 2em;">
<p>Data Umbrella Tutorial</p>
</div>
<div style="font-size: 1.2em; margin-top: 2em;">
<p>Christopher Fonnesbeck<br> <span style="font-size: 0.9em; color: #888;">PyMC Labs</span></p>
</div>
</div>
</section>
<section id="what-well-learn-today" class="slide level2">
<h2>What We‚Äôll Learn Today</h2>
<div style="font-size: 0.9em; margin-top: 1em;">
<ul>
<li>üß† <strong>Bayesian Thinking</strong> - Understanding uncertainty</li>
<li>üìä <strong>Data Analysis</strong> - Real-world examples<br>
</li>
<li>üîß <strong>Practical Skills</strong> - Building real models</li>
<li>üöÄ <strong>Best Practices</strong> - Avoiding pitfalls</li>
</ul>
</div>
<aside class="notes">
<p>This tutorial is designed to be practical and hands-on. We‚Äôll start with the basics but quickly move to real examples.</p>
<p>The four key areas we‚Äôll focus on:</p>
<ol type="1">
<li><p>Bayesian Thinking: Understanding how to think in terms of uncertainty, priors, and updating beliefs with data.</p></li>
<li><p>Practical Skills: You‚Äôll learn to write PyMC code, run MCMC samplers, and interpret results.</p></li>
<li><p>Data Analysis: We‚Äôll work with actual datasets and solve real problems, not just toy examples.</p></li>
<li><p>Best Practices: I‚Äôll share common mistakes I see in the field and how to avoid them.</p></li>
</ol>
<p>This isn‚Äôt just about learning PyMC syntax - it‚Äôs about becoming a better data scientist who can handle uncertainty properly.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="what-is-pymc" class="slide level2">
<h2>What is PyMC?</h2>
<div class="center">
<div style="font-size: 4em; margin-bottom: 0.5em; margin-top: 1em;">
<p>üêç + üìä + üß† = PyMC</p>
</div>
<div style="font-size: 1.5em; color: #888;">
<p>Python + Statistics + Probabilistic Thinking</p>
</div>
</div>
<aside class="notes">
<p>PyMC is where Python meets probabilistic programming.</p>
<p>It‚Äôs fundamentally different from traditional statistical packages: - Instead of point estimates, we work with distributions - Instead of p-values, we get credible intervals - Instead of assuming our models are correct, we quantify our uncertainty</p>
<p>PyMC makes Bayesian modeling accessible by providing: - Intuitive model specification using Python syntax - Automatic differentiation for efficient computation - State-of-the-art MCMC algorithms (especially NUTS) - Seamless integration with the Python data science ecosystem - Excellent visualization tools through ArviZ</p>
<p>Think of it as a way to build models that explicitly handle uncertainty at every step.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="why-bayesian-modeling" class="slide level2">
<h2>Why Bayesian Modeling?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>üìà Traditional Approach</strong></p>
<ul>
<li>Point estimates</li>
<li>p-values<br>
</li>
<li>Confidence intervals*</li>
<li>Null hypothesis testing</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>üéØ Bayesian Approach</strong></p>
<ul>
<li>Full distributions</li>
<li>Probability statements</li>
<li>Credible intervals</li>
<li>Direct inference</li>
</ul>
</div></div>
<aside class="notes">
<p>The Bayesian approach is fundamentally more intuitive and informative:</p>
<p>Traditional Statistics: - Gives you point estimates with error bars - p-values are confusing (what‚Äôs the probability that the null hypothesis is true? NOT what p-values tell you!) - Confidence intervals have a weird interpretation: ‚ÄúIf we repeated this study 100 times, 95% of the confidence intervals would contain the true value‚Äù - Focuses on rejecting null hypotheses rather than quantifying effects</p>
<p>Bayesian Statistics: - Gives you the full distribution of possible parameter values - You can make direct probability statements: ‚ÄúThere‚Äôs a 95% chance the effect is between X and Y‚Äù - Credible intervals have the intuitive interpretation you want - You can incorporate prior knowledge naturally - You get uncertainty quantification for free</p>
<p>The Bayesian approach answers the questions you actually want to ask about your data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-world-applications" class="slide level2">
<h2>Real-World Applications</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>üè• Healthcare</strong> - Clinical trial design - Drug dosing optimization<br>
- Epidemiological modeling</p>
<p><strong>üß¨ Science</strong> - Parameter estimation - Model comparison - Experimental design</p>
</div><div class="column" style="width:50%;">
<p><strong>üí∞ Finance</strong> - Risk modeling - Portfolio optimization - Credit scoring</p>
<p><strong>üì± Tech</strong> - A/B testing - Recommendation systems - Anomaly detection</p>
</div></div>
<aside class="notes">
<p>PyMC is used across many industries because uncertainty is everywhere:</p>
<p>Healthcare: - Clinical trials need to account for patient variability - Drug dosing must be personalized based on patient characteristics - Epidemiological models help track disease spread with uncertainty - Diagnostic tests have false positive/negative rates that need proper handling</p>
<p>Finance: - Risk models must quantify uncertainty in potential losses - Portfolio optimization needs to account for parameter uncertainty - Credit scoring benefits from hierarchical models for different populations - Market forecasting explicitly acknowledges we don‚Äôt know the future</p>
<p>Science: - Parameter estimation with proper uncertainty quantification - Model comparison using information criteria and cross-validation - Experimental design optimizes information gain - Meta-analysis combines evidence from multiple studies</p>
<p>Technology: - A/B testing with proper statistical inference - Recommendation systems that adapt to user preferences - Anomaly detection that adapts to changing baselines - User behavior models that capture individual differences</p>
<p>The common thread: all these applications involve uncertainty that needs to be properly quantified and propagated.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="installation-setup" class="title-slide slide level1 center">
<h1>üì¶ Installation &amp; Setup</h1>
<div class="center">
<div style="font-size: 3em; margin-top: 1em;">
<p>Let‚Äôs get you up and running!</p>
</div>
</div>
<aside class="notes">
<p>Before we dive into modeling, let‚Äôs make sure everyone has PyMC properly installed and configured.</p>
<p>There are a few different ways to install PyMC, and the choice depends on your setup and needs. I‚Äôll show you the recommended approaches and help you troubleshoot common issues.</p>
<p>Don‚Äôt worry if you run into problems - PyMC has some complex dependencies, and installation issues are common. We‚Äôll work through them together.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="recommended-installation" class="slide level2">
<h2>üöÄ Recommended Installation</h2>
<div class="center">
<div style="font-family: monospace; font-size: 2.5em; margin-bottom: 0.5em;">
<p>conda install -c conda-forge pymc</p>
</div>
<div style="font-size: 1.1em; color: #888; margin-bottom: 1em;">
<p>(conda-forge is the official recommended method)</p>
</div>
<div style="font-size: 1.1em;">
<p>‚úÖ Best dependency management<br> ‚úÖ Includes ArviZ automatically<br> ‚úÖ Most stable installation</p>
</div>
</div>
<aside class="notes">
<p>The PyMC team officially recommends conda-forge for installation:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href=""></a><span class="co"># Create a new environment (recommended)</span></span>
<span id="cb1-2"><a href=""></a><span class="ex">conda</span> create <span class="at">-c</span> conda-forge <span class="at">-n</span> pymc_env <span class="st">"pymc&gt;=5"</span></span>
<span id="cb1-3"><a href=""></a><span class="ex">conda</span> activate pymc_env</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Or install in existing environment:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href=""></a><span class="ex">conda</span> install <span class="at">-c</span> conda-forge pymc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Why conda-forge is recommended: - Better handling of complex numerical dependencies (BLAS, LAPACK) - Pre-compiled binaries avoid compilation issues - Consistent versions across the numerical Python stack - Official PyMC recommendation per documentation</p>
<p>For advanced users who need cutting-edge features:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href=""></a><span class="co"># Development installation in existing conda env</span></span>
<span id="cb3-2"><a href=""></a><span class="ex">pip</span> install <span class="at">-e</span> .  <span class="co"># Only for contributors</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Never use regular conda channel - always use conda-forge.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="sampling-backends-libraries" class="slide level2">
<h2>Sampling Backends &amp; Libraries</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>üîß PyTensor (Default)</strong> - CPU-based, most stable - Works everywhere<br>
- All PyMC features supported</p>
<p><strong>‚ö° JAX + NumPyro</strong> - GPU/TPU acceleration - <code>conda install numpyro</code> - Some limitations</p>
</div><div class="column" style="width:50%;">
<p><strong>üöÄ Nutpie</strong> - Rust + Numba performance - <code>conda install -c conda-forge nutpie</code> - CPU-optimized NUTS</p>
<p><strong>‚ö´ BlackJAX</strong> - JAX-based samplers - <code>conda install blackjax</code> - Advanced MCMC methods</p>
</div></div>
<aside class="notes">
<p>PyMC supports multiple computational backends and sampling libraries:</p>
<ol type="1">
<li>PyTensor Backend (Default):
<ul>
<li>CPU-based using NumPy/SciPy</li>
<li>Most stable and battle-tested</li>
<li>Works on any system with Python</li>
<li>All PyMC features fully supported</li>
<li>Best choice for learning and most applications</li>
</ul></li>
<li>JAX Backend with NumPyro:
<ul>
<li>GPU and TPU acceleration</li>
<li>Install: conda install numpyro</li>
<li>5-10x faster for large models</li>
<li>JIT compilation for speed</li>
<li>Some PyMC features may have limitations</li>
</ul></li>
<li>Nutpie (Fast CPU sampling):
<ul>
<li>Rust-based NUTS implementation with Numba</li>
<li>Install: conda install -c conda-forge nutpie</li>
<li>Optimized for CPU performance</li>
<li>Faster than default PyTensor for many models</li>
</ul></li>
<li>BlackJAX (Advanced JAX samplers):
<ul>
<li>JAX-based sampling library</li>
<li>Install: conda install blackjax</li>
<li>Advanced MCMC algorithms</li>
<li>Useful for research and specialized sampling</li>
</ul></li>
</ol>
<p>For this tutorial, we‚Äôll use the default PyTensor backend since it works reliably for everyone and handles all our examples perfectly.</p>
<p>You can explore faster backends later when working with larger, more complex models.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="test-your-installation" class="slide level2">
<h2>‚úÖ Test Your Installation</h2>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href=""></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb4-2"><a href=""></a><span class="bu">print</span>(<span class="ss">f"PyMC version: </span><span class="sc">{</span>pm<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-3"><a href=""></a></span>
<span id="cb4-4"><a href=""></a><span class="im">import</span> arviz <span class="im">as</span> az</span>
<span id="cb4-5"><a href=""></a><span class="bu">print</span>(<span class="ss">f"ArviZ version: </span><span class="sc">{</span>az<span class="sc">.</span>__version__<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-6"><a href=""></a></span>
<span id="cb4-7"><a href=""></a><span class="co"># Quick test</span></span>
<span id="cb4-8"><a href=""></a>x <span class="op">=</span> pm.Normal.dist(mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-9"><a href=""></a><span class="bu">print</span>(<span class="ss">f"Test sample: </span><span class="sc">{</span>pm<span class="sc">.</span>draw(x, draws<span class="op">=</span><span class="dv">3</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="fragment">
<div style="font-size: 1.5em; margin-top: 1em; text-align: center; color: #4caf50;">
<p>üéâ If this runs, you‚Äôre ready!</p>
</div>
</div>
<aside class="notes">
<p>Let‚Äôs verify your installation works correctly.</p>
<p>First, check versions: - PyMC version should be 5.x.x (we need version 5) - ArviZ version should be 0.15+ for best compatibility</p>
<p>Then run a quick test to make sure the basic functionality works: - Create a simple Normal distribution - Draw some samples from it - If you see an array of random numbers, everything is working!</p>
<p>Common issues and solutions:</p>
<p>If you get import errors: - Try: pip install ‚Äìupgrade pymc arviz - Or: conda update pymc arviz</p>
<p>If you get compilation errors: - On Windows: install Microsoft Visual C++ Build Tools - On Mac: install Xcode command line tools (xcode-select ‚Äìinstall) - On Linux: install build-essential package</p>
<p>If sampling is very slow: - This is normal for the first run (compilation overhead) - Subsequent runs should be much faster</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="development-setup" class="slide level2">
<h2>üõ†Ô∏è Development Setup</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>üìì Jupyter Notebooks</strong><br>
<em>Recommended for learning</em></p>
<ul>
<li>‚úÖ Interactive exploration</li>
<li>‚úÖ Immediate plot display<br>
</li>
<li>‚úÖ Great for tutorials</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>üÜö VS Code + Jupyter</strong><br>
<em>Best of both worlds</em></p>
<ul>
<li>‚úÖ Code completion</li>
<li>‚úÖ Git integration</li>
<li>‚úÖ Notebook support</li>
</ul>
</div></div>
<aside class="notes">
<p>For Bayesian modeling, your development environment matters:</p>
<p>Jupyter Notebooks: - Perfect for exploratory data analysis - Interactive plots work seamlessly - Easy to iterate on models - Great for sharing results - ArviZ plots display beautifully - Recommended for learning PyMC</p>
<p>VS Code: - Better for production code - Excellent debugging capabilities - Smart code completion for PyMC - Integrated version control - Can run notebooks natively - Better for larger projects</p>
<p>Other good options: - PyCharm: Great IDE features, good for complex projects - Google Colab: Free GPU access, good for large models - Spyder: Popular in scientific computing</p>
<p>For this tutorial, either Jupyter or VS Code will work great. Choose what you‚Äôre most comfortable with.</p>
<p>Pro tip: Start with Jupyter for exploration, then move to VS Code when you want to turn your analysis into reusable code.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="troubleshooting-common-issues" class="slide level2">
<h2>üîß Troubleshooting Common Issues</h2>
<p><strong>üí• Import Errors</strong></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href=""></a><span class="ex">conda</span> update <span class="at">-c</span> conda-forge pymc arviz</span>
<span id="cb5-2"><a href=""></a><span class="ex">pip</span> install <span class="at">--upgrade</span> pymc arviz</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>‚ö†Ô∏è Windows g++ Compiler Warning</strong></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource bash number-lines code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><a href=""></a><span class="ex">conda</span> install m2w64-toolchain</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><em>Fixes severe performance degradation</em></p>
<p><strong>üñ•Ô∏è Platform Notes</strong> - <strong>Mac M1/M2:</strong> Use conda-forge only<br>
- <strong>Linux:</strong> Generally smooth<br>
- <strong>Colab:</strong> May need runtime restart</p>
<p><strong>üîç Need Help?</strong> ‚Üí discourse.pymc.io</p>
<aside class="notes">
<p>Installation issues are the most common beginner pain points - here‚Äôs what actually works:</p>
<p>Windows g++ Compiler Warning: - Single most frequent issue: ‚ÄúWARNING (pytensor.configdefaults): g++ not available‚Äù - Causes severe performance degradation (10-100x slower) - Solution: conda install m2w64-toolchain in your PyMC environment - This is a PyMC-specific issue, not general Python</p>
<p>Platform-Specific Issues: - Mac M1/M2: BLAS library conflicts, avoid MKL packages, use conda-forge exclusively - Linux: Generally smoothest installation experience - Google Colab: Pre-installed packages conflict, may need runtime restart after pip install</p>
<p>Universal Best Practice: - Always create dedicated environment: conda create -c conda-forge -n pymc_env ‚Äúpymc&gt;=5‚Äù python=3.10 - PyMC‚Äôs complex dependency chain requires conda-forge for reliable installation - pip installations frequently fail with BLAS or Unicode issues</p>
<p>Import/Version Errors: - Try: conda update -c conda-forge pymc arviz - If persistent: create fresh environment - Never use regular conda channel - always conda-forge</p>
<p>Getting Help: - discourse.pymc.io is extremely beginner-friendly - Include full error messages and environment info - Most installation issues have been solved before</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="pymc-fundamentals" class="title-slide slide level1 center">
<h1>üß† PyMC Fundamentals</h1>
<div class="center">
<div style="font-size: 3em; margin-top: 1em;">
<p>The building blocks of Bayesian models</p>
</div>
</div>
<aside class="notes">
<p>Now that we have PyMC installed, let‚Äôs understand how it works.</p>
<p>PyMC has a few core concepts that are essential to understand: - Model containers that hold everything together - Random variables that represent unknown quantities - Distributions that encode our assumptions - Observed data that updates our beliefs</p>
<p>We‚Äôll start simple and build up complexity gradually. By the end of this section, you‚Äôll understand how PyMC thinks about statistical models.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-model-container" class="slide level2">
<h2>The Model Container</h2>
<div class="center">
<div style="font-size: 4em; margin-bottom: 0.5em;">
<p>üì¶</p>
</div>
</div>
<div class="sourceCode" id="cb7" data-code-line-numbers="1|2-3|5-6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href=""></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb7-2"><a href=""></a>    <span class="co"># All random variables go here</span></span>
<span id="cb7-3"><a href=""></a>    mu <span class="op">=</span> pm.Normal(<span class="st">"mu"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb7-4"><a href=""></a>    </span>
<span id="cb7-5"><a href=""></a>    <span class="co"># PyMC tracks relationships automatically</span></span>
<span id="cb7-6"><a href=""></a>    x <span class="op">=</span> pm.Normal(<span class="st">"x"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span><span class="dv">1</span>, observed<span class="op">=</span>data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside class="notes">
<p>The Model container is PyMC‚Äôs way of organizing your statistical model.</p>
<p>Key points: - Uses Python‚Äôs <code>with</code> statement (context manager) - Everything defined inside becomes part of the model - PyMC automatically tracks variable relationships - Variables must have unique names (strings) - The model builds a computational graph behind the scenes</p>
<p>Think of it like a recipe: - The model is your cookbook - Each variable is an ingredient - PyMC figures out how to combine everything</p>
<p>You can have multiple models in the same script, each with their own variables and parameters.</p>
<p>The model context is where the magic happens - PyMC builds a directed acyclic graph (DAG) that represents all the probabilistic relationships in your model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="random-variables-distributions" class="slide level2">
<h2>Random Variables &amp; Distributions</h2>
<div class="sourceCode" id="cb8" data-code-line-numbers="1-2|4-5|7-8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href=""></a><span class="co"># Unobserved (parameters to estimate)</span></span>
<span id="cb8-2"><a href=""></a>mu <span class="op">=</span> pm.Normal(<span class="st">"mu"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb8-3"><a href=""></a>sigma <span class="op">=</span> pm.HalfNormal(<span class="st">"sigma"</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb8-4"><a href=""></a></span>
<span id="cb8-5"><a href=""></a><span class="co"># Deterministic transformations</span></span>
<span id="cb8-6"><a href=""></a>scaled_mu <span class="op">=</span> pm.Deterministic(<span class="st">"scaled_mu"</span>, mu <span class="op">*</span> <span class="dv">2</span>)</span>
<span id="cb8-7"><a href=""></a></span>
<span id="cb8-8"><a href=""></a><span class="co"># Observed (your data)</span></span>
<span id="cb8-9"><a href=""></a>y <span class="op">=</span> pm.Normal(<span class="st">"y"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span>sigma, observed<span class="op">=</span>data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside class="notes">
<p>PyMC has three main types of variables:</p>
<ol type="1">
<li>Unobserved Random Variables (Parameters):
<ul>
<li>These are what you want to estimate</li>
<li>Have prior distributions that encode your beliefs</li>
<li>Example: mu ~ Normal(0, 10) says we think mu is around 0, but could be as far as ¬±20 with reasonable probability</li>
</ul></li>
<li>Deterministic Variables:
<ul>
<li>Functions of other variables</li>
<li>No additional randomness</li>
<li>Useful for transformations and derived quantities</li>
<li>Example: scaled_mu = mu * 2</li>
</ul></li>
<li>Observed Variables (Data):
<ul>
<li>Your actual data</li>
<li>Fixed during inference</li>
<li>Connected to parameters through the likelihood</li>
<li>Example: y ~ Normal(mu, sigma) where y is your observed data</li>
</ul></li>
</ol>
<p>The key insight: you‚Äôre building a generative model. You‚Äôre saying ‚Äúthis is how I think the data was generated‚Äù and then inverting that process to learn about the parameters.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="distribution-zoo" class="slide level2">
<h2>Distribution Zoo ü¶Å</h2>

<img data-src="./public/plots/distributions/distribution_zoo.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>PyMC provides a comprehensive set of probability distributions:</p>
<p>Continuous Distributions: - Normal: The workhorse, symmetric, unbounded - Beta: For probabilities and proportions (0 to 1) - Exponential: For positive values, waiting times - Gamma: Positive values with more flexibility than exponential - Student-t: Like normal but with heavier tails - Many more: Uniform, LogNormal, Cauchy, etc.</p>
<p>Discrete Distributions: - Poisson: Count data, events per time period - Binomial: Success/failure with fixed number of trials - Categorical: Multiple discrete outcomes - Bernoulli: Single success/failure trial</p>
<p>Choosing distributions: - Match the support to your data (positive, bounded, etc.) - Consider the shape you expect - Start simple (Normal is often a good default) - Use domain knowledge when available</p>
<p>Each distribution has parameters that control its shape and location. Understanding these parameters is key to building good models.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="observed-data" class="slide level2">
<h2>Observed Data</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="sourceCode" id="cb9" data-code-line-numbers="1-2|4-5|6-7|8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href=""></a><span class="co"># Your actual data</span></span>
<span id="cb9-2"><a href=""></a>data <span class="op">=</span> np.array([<span class="fl">1.2</span>, <span class="fl">2.3</span>, <span class="fl">1.8</span>, <span class="fl">2.9</span>, <span class="fl">3.1</span>])</span>
<span id="cb9-3"><a href=""></a></span>
<span id="cb9-4"><a href=""></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb9-5"><a href=""></a>    mu <span class="op">=</span> pm.Normal(<span class="st">"mu"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb9-6"><a href=""></a>    sigma <span class="op">=</span> pm.HalfNormal(<span class="st">"sigma"</span>, sigma<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-7"><a href=""></a>    observations <span class="op">=</span> pm.Normal(<span class="st">"obs"</span>, mu<span class="op">=</span>mu, </span>
<span id="cb9-8"><a href=""></a>                           sigma<span class="op">=</span>sigma, observed<span class="op">=</span>data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column" style="width:40%;">
<div style="margin-top: 2em;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
Key Points
</div>
<ul style="font-size: 0.9em;">
<li>
üéØ <code>observed=data</code> makes it a likelihood
</li>
<li>
üìä Data shape must match distribution
</li>
<li>
üîó Links parameters to your actual data
</li>
<li>
‚ö° This is where Bayes‚Äô theorem happens!
</li>
</ul>
</div>
</div></div>
<aside class="notes">
<p>The <code>observed</code> argument is where your data meets your model:</p>
<p>What happens with observed=data: - Tells PyMC these values are fixed and known - Creates the likelihood function automatically - Links your parameters (mu, sigma) to your actual observations - This is where Bayes‚Äô theorem gets applied</p>
<p>Important considerations: - Data shape must match what the distribution expects - Missing data (NaN) is handled automatically - You can have multiple observed variables - The observed variable name is just for reference</p>
<p>Behind the scenes: - PyMC computes log P(data | parameters) for each MCMC sample - Combined with priors P(parameters), this gives you the posterior - The observed data never changes during sampling - Only the parameters (mu, sigma) are updated</p>
<p>This is the heart of Bayesian inference: updating our beliefs about parameters based on observed data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-handling-pitfalls" class="slide level2">
<h2>üìä Data Handling Pitfalls</h2>
<p><strong>‚ùå Wrong: Pandas inside model</strong></p>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href=""></a><span class="cf">with</span> pm.Model():</span>
<span id="cb10-2"><a href=""></a>    means <span class="op">=</span> df.groupby(<span class="st">'category'</span>).mean()  <span class="co"># This fails!</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>‚úÖ Correct: Prepare data first</strong></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href=""></a>means <span class="op">=</span> df.groupby(<span class="st">'category'</span>).mean().values</span>
<span id="cb11-2"><a href=""></a><span class="cf">with</span> pm.Model():</span>
<span id="cb11-3"><a href=""></a>    data <span class="op">=</span> pm.Data(<span class="st">"data"</span>, means)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>üîß Key Patterns:</strong> - Complete pandas operations <strong>outside</strong> model context - Convert to numpy arrays before entering model - Use <code>pm.Data()</code> for data that might change - Use <code>pt.where()</code> for missing data (JAX/NumPyro compatible)</p>
<aside class="notes">
<p>Data preparation errors reflect fundamental misunderstandings about PyMC‚Äôs computational model:</p>
<p>The Core Problem: - PyMC operates on symbolic tensors, not pandas DataFrames - Most pervasive mistake: using pandas operations inside model context - df.groupby(‚Äòcategory‚Äô).mean() inside with pm.Model() fails - PyMC needs fixed numpy arrays or tensor operations</p>
<p>The Solution Pattern: 1. Complete ALL pandas operations outside the model context 2. Convert results to numpy arrays (.values) 3. Use pm.Data() for data that needs updating 4. Enter the model context only with prepared tensors</p>
<p>Missing Data Handling: - JAX/NumPyro backends don‚Äôt support boolean masks - Use pt.where() for conditional operations (works with all backends) - Or explicitly model missing values as latent variables - Avoid numpy-style masking operations</p>
<p>Categorical Variables: - Don‚Äôt one-hot encode everything for PyMC - Use pd.factorize() for index-based encoding - Combine with coordinate systems for meaningful labels<br>
- More efficient and scales better for hierarchical models</p>
<p>Best Practice Workflow: data_prep.py -&gt; clean pandas operations model.py -&gt; pure PyMC tensor operations This separation prevents most data handling errors.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-bayesian-recipe" class="slide level2">
<h2>The Bayesian Recipe</h2>
<div class="center">
<div style="font-size: 2.5em; margin-bottom: 1em;">
<p>Prior √ó Likelihood = Posterior</p>
</div>
</div>
<div class="sourceCode" id="cb12" data-code-line-numbers="2-3|5-6|8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href=""></a><span class="cf">with</span> pm.Model() <span class="im">as</span> model:</span>
<span id="cb12-2"><a href=""></a>    <span class="co"># Prior: What we believe before seeing data</span></span>
<span id="cb12-3"><a href=""></a>    mu <span class="op">=</span> pm.Normal(<span class="st">"mu"</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb12-4"><a href=""></a>    </span>
<span id="cb12-5"><a href=""></a>    <span class="co"># Likelihood: How we think data was generated</span></span>
<span id="cb12-6"><a href=""></a>    y <span class="op">=</span> pm.Normal(<span class="st">"y"</span>, mu<span class="op">=</span>mu, sigma<span class="op">=</span><span class="dv">1</span>, observed<span class="op">=</span>data)</span>
<span id="cb12-7"><a href=""></a>    </span>
<span id="cb12-8"><a href=""></a>    <span class="co"># Posterior: Updated beliefs (computed by MCMC)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside class="notes">
<p>This is the heart of Bayesian statistics:</p>
<p>Prior: - Your beliefs before seeing the data - Can be informative (based on domain knowledge) or uninformative (letting data dominate) - Example: mu ~ Normal(0, 10) says we think mu is probably near 0</p>
<p>Likelihood: - Your model of how the data was generated - Given parameters, what‚Äôs the probability of observing your data? - Example: y ~ Normal(mu, 1) says each observation comes from a normal distribution</p>
<p>Posterior: - Your updated beliefs after seeing the data - Combines prior knowledge with information from data - This is what MCMC sampling gives you - Automatically balances prior and likelihood based on data quality</p>
<p>Bayes‚Äô theorem: P(parameters | data) ‚àù P(data | parameters) √ó P(parameters)</p>
<p>The beauty: everything is probabilistic, so you get full uncertainty quantification for free.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="pymc-arviz-integration" class="slide level2">
<h2>PyMC ‚ù§Ô∏è ArviZ Integration</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
üé® PyMC
</div>
<ul style="font-size: 1.1em;">
<li>
Model specification
</li>
<li>
MCMC sampling
</li>
<li>
Prior/posterior predictive
</li>
<li>
Model comparison
</li>
</ul>
</div><div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
üìä ArviZ
</div>
<ul style="font-size: 1.1em;">
<li>
Visualization
</li>
<li>
Diagnostics
</li>
<li>
Model checking
</li>
<li>
Summary statistics
</li>
</ul>
</div></div>
<div class="center">
<div style="font-size: 1.1em; color: #888; margin-top: 2em;">
<p>Seamless workflow: PyMC ‚Üí InferenceData ‚Üí ArviZ</p>
</div>
</div>
<aside class="notes">
<p>PyMC and ArviZ work together seamlessly:</p>
<p>PyMC handles: - Defining your statistical model - Running MCMC sampling (NUTS algorithm) - Prior and posterior predictive sampling - Model comparison metrics (LOO, WAIC)</p>
<p>ArviZ provides: - Publication-quality plots - Comprehensive diagnostics - Model checking tools - Summary statistics and tables</p>
<p>The connection is through InferenceData: - A standardized format for Bayesian analysis results - Contains posterior samples, prior samples, observed data, etc. - Works with PyMC, Stan, TensorFlow Probability, and more - Makes your analysis reproducible and shareable</p>
<p>Typical workflow: 1. Define model in PyMC 2. Sample with pm.sample() ‚Üí InferenceData object 3. Visualize and diagnose with ArviZ 4. Iterate and improve your model</p>
<p>This separation of concerns lets each tool focus on what it does best.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="building-your-first-model" class="title-slide slide level1 center">
<h1>üèóÔ∏è Building Your First Model</h1>
<div class="center">
<div style="font-size: 1.8em; margin-top: 0.5em;">
<p>From data to insights with real examples</p>
</div>
</div>
<aside class="notes">
<p>Now comes the fun part - building and fitting actual Bayesian models!</p>
<p>We‚Äôll work through a complete example from start to finish: - Understand the problem and data - Specify a Bayesian model - Check our priors make sense - Sample from the posterior - Diagnose potential issues - Interpret results - Make predictions</p>
<p>This isn‚Äôt a toy example - we‚Äôll use real data and go through all the steps you‚Äôd follow in practice.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-bioassay-problem" class="slide level2">
<h2>üß™ The Bioassay Problem</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
The Question
</div>
<div style="font-size: 1.1em;">
<p>How does drug dose affect mortality in lab animals?</p>
</div>
</div><div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
The Data
</div>
<div style="font-size: 1.1em; margin-top: 1em;">
<div>
<strong>Dose:</strong> [-0.86, -0.3, -0.05, 0.73]
</div>
<div>
<strong>Animals:</strong> [5, 5, 5, 5]
</div>
<div>
<strong>Deaths:</strong> [0, 1, 3, 5]
</div>
</div>
</div></div>
<div class="center">
<div style="font-size: 1.1em; color: #888; margin-top: 2em;">
<p>Classic dose-response modeling problem</p>
</div>
</div>
<aside class="notes">
<p>This is a classic problem in toxicology and pharmacology:</p>
<p>The Setup: - We have 4 different dose levels (on log scale, centered) - 5 animals tested at each dose - We count how many animals died at each dose - Goal: model the dose-response relationship</p>
<p>Why this matters: - Understand drug safety and efficacy - Determine safe dosage ranges - Predict effects at untested doses - Quantify uncertainty in our predictions</p>
<p>The Data: - Dose -0.86: 0 out of 5 animals died (0% mortality) - Dose -0.3: 1 out of 5 animals died (20% mortality) - Dose -0.05: 3 out of 5 animals died (60% mortality) - Dose 0.73: 5 out of 5 animals died (100% mortality)</p>
<p>Clear dose-response relationship, but we want to model this probabilistically to: - Get uncertainty estimates - Make predictions for new doses - Understand the shape of the dose-response curve</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="building-the-model" class="slide level2">
<h2>Building the Model</h2>
<div class="sourceCode" id="cb13" data-code-line-numbers="1-4|6-7|9-10|11-12|14-15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href=""></a><span class="co"># The data</span></span>
<span id="cb13-2"><a href=""></a>dose <span class="op">=</span> np.array([<span class="op">-</span><span class="fl">0.86</span>, <span class="op">-</span><span class="fl">0.3</span>, <span class="op">-</span><span class="fl">0.05</span>, <span class="fl">0.73</span>])</span>
<span id="cb13-3"><a href=""></a>n_animals <span class="op">=</span> np.array([<span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">5</span>])</span>
<span id="cb13-4"><a href=""></a>n_deaths <span class="op">=</span> np.array([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>])</span>
<span id="cb13-5"><a href=""></a></span>
<span id="cb13-6"><a href=""></a><span class="cf">with</span> pm.Model() <span class="im">as</span> bioassay_model:</span>
<span id="cb13-7"><a href=""></a>    <span class="co"># Priors for intercept and slope</span></span>
<span id="cb13-8"><a href=""></a>    alpha <span class="op">=</span> pm.Normal(<span class="st">'alpha'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb13-9"><a href=""></a>    beta <span class="op">=</span> pm.Normal(<span class="st">'beta'</span>, mu<span class="op">=</span><span class="dv">0</span>, sigma<span class="op">=</span><span class="fl">2.5</span>)</span>
<span id="cb13-10"><a href=""></a>    </span>
<span id="cb13-11"><a href=""></a>    <span class="co"># Logistic regression model</span></span>
<span id="cb13-12"><a href=""></a>    theta <span class="op">=</span> pm.invlogit(alpha <span class="op">+</span> beta <span class="op">*</span> dose)</span>
<span id="cb13-13"><a href=""></a>    </span>
<span id="cb13-14"><a href=""></a>    <span class="co"># Binomial likelihood</span></span>
<span id="cb13-15"><a href=""></a>    deaths <span class="op">=</span> pm.Binomial(<span class="st">'deaths'</span>, n<span class="op">=</span>n_animals, p<span class="op">=</span>theta, observed<span class="op">=</span>n_deaths)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside class="notes">
<p>Let‚Äôs build this step by step:</p>
<p>The Data: - dose: log-transformed and centered doses - n_animals: number of animals at each dose (5 each) - n_deaths: observed deaths at each dose</p>
<p>The Model Structure:</p>
<ol type="1">
<li>Priors:
<ul>
<li>alpha: intercept (log-odds at dose=0)</li>
<li>beta: slope (how log-odds change with dose)</li>
<li>Normal(0, 2.5) is weakly informative - allows wide range but prevents extreme values</li>
</ul></li>
<li>Linear Predictor:
<ul>
<li>alpha + beta * dose gives log-odds of death</li>
<li>This is the standard logistic regression setup</li>
</ul></li>
<li>Inverse Logit Transformation:
<ul>
<li>Converts log-odds to probabilities (0 to 1 range)</li>
<li>theta[i] = probability of death at dose[i]</li>
</ul></li>
<li>Likelihood:
<ul>
<li>Binomial distribution: n_deaths ~ Binomial(n_animals, theta)</li>
<li>This says: at each dose, deaths follow a binomial distribution</li>
<li>Like flipping n_animals coins, each with probability theta of ‚Äúdeath‚Äù</li>
</ul></li>
</ol>
<p>This is a generalized linear model (GLM) with logit link - a Bayesian version of logistic regression.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="common-modeling-errors" class="slide level2">
<h2>‚ö†Ô∏è Common Modeling Errors</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="background-color: #c62828; padding: 1em; border-radius: 0.5em;">
<div style="color: #ffcdd2; font-weight: bold; margin-bottom: 0.5em;">
üî¢ Shape Mismatches
</div>
<div style="font-size: 0.9em; color: #ffcdd2;">
<pre><code>&lt;code&gt;ValueError: Input dimension mis-match&lt;/code&gt;&lt;br&gt;
Matrix vs element-wise operations&lt;br&gt;
Explicit shape specification needed</code></pre>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="background-color: #ff6f00; padding: 1em; border-radius: 0.5em;">
<div style="color: #fff3e0; font-weight: bold; margin-bottom: 0.5em;">
üìä Broadcasting Issues
</div>
<div style="font-size: 0.9em; color: #fff3e0;">
<pre><code>Mixing &lt;code&gt;shape&lt;/code&gt; and &lt;code&gt;dims&lt;/code&gt;&lt;br&gt;
Inconsistent coordinate systems&lt;br&gt;
Check tensor shapes explicitly</code></pre>
</div>
</div>
</div></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href=""></a><span class="co"># ‚ùå Wrong: element-wise when you want matrix multiplication  </span></span>
<span id="cb16-2"><a href=""></a>mu <span class="op">=</span> X <span class="op">*</span> beta  </span>
<span id="cb16-3"><a href=""></a></span>
<span id="cb16-4"><a href=""></a><span class="co"># ‚úÖ Correct: explicit matrix operations</span></span>
<span id="cb16-5"><a href=""></a>beta <span class="op">=</span> pm.Normal(<span class="st">'beta'</span>, mu<span class="op">=</span><span class="dv">0</span>, sd<span class="op">=</span><span class="dv">1</span>, shape<span class="op">=</span>(n_features,))</span>
<span id="cb16-6"><a href=""></a>mu <span class="op">=</span> pm.math.dot(X, beta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside class="notes">
<p>Shape mismatches are the most common modeling error after installation:</p>
<p>Matrix Multiplication Confusion: - Beginners confuse * (element-wise) with matrix multiplication - ValueError: Input dimension mis-match is the telltale sign - Always be explicit: use pm.math.dot() for matrix operations - Specify shapes explicitly: shape=(n_features,) not just scalar</p>
<p>Broadcasting Problems: - PyMC has strict broadcasting rules unlike NumPy - Don‚Äôt mix shape and dims parameters inconsistently - Understand positional broadcasting vs named dimensions - When in doubt, check tensor shapes with .eval()</p>
<p>Best Practices: - Always specify shapes for coefficient vectors: shape=(n_features,) - Use pm.math functions instead of numpy equivalents inside models - Test with simple data first to catch shape errors early - Be explicit about broadcasting operations</p>
<p>The pattern: beta with shape=(n_features,) and pm.math.dot(X, beta) works reliably for linear models.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="prior-predictive-check" class="slide level2">
<h2>Prior Predictive Check</h2>

<img data-src="./public/plots/bioassay/prior_predictive.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Before fitting the model, let‚Äôs check if our priors make sense:</p>
<p>What we‚Äôre looking at: - Each line shows a possible dose-response curve under our priors - X-axis: dose (log scale) - Y-axis: probability of death (0 to 1)</p>
<p>What we want to see: - Curves that cover reasonable ranges - Mostly monotonic relationships (higher dose ‚Üí higher death probability) - No extreme or impossible behaviors</p>
<p>What we observe: - Good variety of curves from gentle to steep - Most are monotonically increasing (good!) - Some flat or slightly decreasing curves (that‚Äôs okay - priors should be somewhat agnostic) - Probability ranges from 0 to 1 as expected</p>
<p>This looks reasonable! Our priors allow for a wide range of dose-response relationships without being too restrictive.</p>
<p>If we saw problems (e.g., all curves were flat, or probabilities went outside [0,1]), we‚Äôd need to adjust our priors.</p>
<p>Prior predictive checks are crucial - they catch modeling mistakes before you waste time on sampling.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="sampling-the-posterior" class="slide level2">
<h2>Sampling the Posterior</h2>
<div class="sourceCode" id="cb17" data-code-line-numbers="1-2|4-5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href=""></a><span class="cf">with</span> bioassay_model:</span>
<span id="cb17-2"><a href=""></a>    trace <span class="op">=</span> pm.sample(<span class="dv">2000</span>, tune<span class="op">=</span><span class="dv">1000</span>, chains<span class="op">=</span><span class="dv">4</span>, random_seed<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb17-3"><a href=""></a></span>
<span id="cb17-4"><a href=""></a><span class="co"># PyMC automatically:</span></span>
<span id="cb17-5"><a href=""></a><span class="co"># ‚úì Chose NUTS sampler    ‚úì Tuned parameters</span></span>
<span id="cb17-6"><a href=""></a><span class="co"># ‚úì Ran 4 parallel chains ‚úì Checked convergence</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="center">
<div style="font-size: 1.5em; margin-top: 1em;">
<p>‚ö° Modern MCMC is (mostly) automatic! ‚ö°</p>
</div>
</div>
<aside class="notes">
<p>Time to fit the model using MCMC sampling:</p>
<p>What pm.sample() does: - Automatically selects NUTS (No-U-Turn Sampler) - state of the art - Runs a tuning phase to find good step sizes and mass matrix - Samples from the posterior using 4 parallel chains - Monitors convergence diagnostics - Returns an InferenceData object with all results</p>
<p>Parameters explained: - 2000: number of posterior samples per chain (after tuning) - tune=1000: number of tuning/warmup samples (discarded) - chains=4: number of parallel chains (helps detect convergence issues) - random_seed=42: for reproducibility</p>
<p>What happens during sampling: 1. Tuning phase (1000 steps): NUTS learns about the posterior geometry 2. Sampling phase (2000 √ó 4 = 8000 total samples): collect posterior samples 3. Convergence checks: R-hat, effective sample size, divergences</p>
<p>Modern MCMC is remarkably robust: - NUTS automatically adapts to the posterior shape - Parallel chains help identify problems - Comprehensive diagnostics catch most issues - Most models ‚Äújust work‚Äù without manual tuning</p>
<p>This is a huge advance over older MCMC methods that required lots of manual tuning.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="trace-plots-checking-convergence" class="slide level2">
<h2>Trace Plots: Checking Convergence</h2>

<img data-src="./public/plots/bioassay/trace_plot.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Trace plots are your first check for sampling problems:</p>
<p>What we‚Äôre looking at: - Left panels: posterior distributions (what we care about) - Right panels: trace plots showing parameter values over MCMC iterations</p>
<p>What we want to see: - ‚ÄúFuzzy caterpillars‚Äù - traces should look like random noise - All chains (different colors) should overlap and explore the same space - No obvious trends, patterns, or getting stuck - Smooth, unimodal posterior distributions</p>
<p>What we observe: - Both alpha and beta show excellent mixing - All 4 chains are exploring the same regions - No signs of convergence problems - Posterior distributions look smooth and reasonable</p>
<p>Signs of problems to watch for: - Chains that don‚Äôt overlap (convergence failure) - Trends in the traces (not stationary) - Chains getting stuck in one region - Very different behavior between chains</p>
<p>Our traces look great! This suggests our MCMC sampling worked well and we can trust our posterior estimates.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="posterior-distributions" class="slide level2">
<h2>Posterior Distributions</h2>

<img data-src="./public/plots/bioassay/posterior_plot.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>Now let‚Äôs look at what we learned about the parameters:</p>
<p>Alpha (Intercept): - Mean around 0.24 - Represents log-odds of death at dose = 0 (center of dose range) - Exp(0.24) / (1 + exp(0.24)) ‚âà 56% probability of death at average dose - Uncertainty: 95% credible interval roughly [-1, 1.4]</p>
<p>Beta (Slope): - Mean around 4.03 - Represents how log-odds change per unit increase in dose - Strong positive relationship: higher dose ‚Üí higher death probability - This is a steep dose-response curve - Uncertainty: 95% credible interval roughly [1.5, 6.9]</p>
<p>Key insights: - There‚Äôs definitely a dose-response relationship (beta &gt; 0 with high confidence) - But there‚Äôs still uncertainty about the exact slope - At the lowest dose, death probability is low but not zero - At the highest dose, death probability is very high</p>
<p>Compare to classical statistics: - Instead of point estimates + standard errors, we get full distributions - Instead of p-values, we can make direct probability statements - ‚ÄúThere‚Äôs a 97.5% chance beta is greater than 1.5‚Äù - much more intuitive!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="parameter-relationships" class="slide level2">
<h2>Parameter Relationships</h2>

<img data-src="./public/plots/bioassay/pair_plot.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>The pair plot shows how parameters relate to each other:</p>
<p>What we‚Äôre looking at: - Scatter plot of alpha vs beta posterior samples - Each point represents one MCMC draw - Contours show the joint posterior density</p>
<p>What we observe: - Slight negative correlation between alpha and beta - This makes sense: if the intercept is higher, the slope can be lower to fit the same data - The correlation isn‚Äôt too strong (good for inference) - Joint distribution looks well-behaved (elliptical, unimodal)</p>
<p>Why parameter correlations matter: - Strong correlations can slow MCMC sampling - Indicate potential identifiability issues - Affect prediction uncertainty - Can suggest model reparameterizations</p>
<p>In our case: - Correlation is mild and not problematic - Both parameters are well-identified by the data - The relationship makes biological sense</p>
<p>This is another sign that our model and sampling worked well. Strong correlations or weird shapes here would suggest problems.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="model-summary" class="slide level2">
<h2>Model Summary</h2>
<div class="sourceCode" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href=""></a>az.summary(trace, var_names<span class="op">=</span>[<span class="st">'alpha'</span>, <span class="st">'beta'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat
alpha  0.241  0.634  -0.985    1.430      0.010    0.008    4266.0    4089.0    1.0
beta   4.034  1.447   1.532    6.869      0.022    0.018    5094.0    4724.0    1.0</code></pre>
<div class="center">
<div style="font-size: 1.5em;">
üéØ Excellent diagnostics!
</div>
</div>
<aside class="notes">
<p>The summary table gives us key information about our posterior and sampling:</p>
<p>Key Statistics: - mean: posterior mean (point estimate) - sd: posterior standard deviation (uncertainty) - hdi_3%, hdi_97%: 94% highest density interval (credible interval)</p>
<p>Diagnostics: - mcse_mean, mcse_sd: Monte Carlo standard error (should be small) - ess_bulk, ess_tail: effective sample size (want &gt; 400, ideally &gt; 1000) - r_hat: potential scale reduction factor (want &lt; 1.01, ideally 1.00)</p>
<p>Our Results: - Both parameters well-estimated with reasonable uncertainty - HDI intervals don‚Äôt include extreme values - Excellent effective sample sizes (4000+) - Perfect R-hat values (1.0) - Low Monte Carlo error</p>
<p>What this means: - Our MCMC sampling was very efficient - We have enough samples for reliable inference - No convergence issues detected - We can trust our posterior estimates</p>
<p>This is what good Bayesian inference looks like - clean diagnostics and interpretable results.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="posterior-predictive-check" class="slide level2">
<h2>Posterior Predictive Check</h2>

<img data-src="./public/plots/bioassay/posterior_predictive.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>The posterior predictive check validates our model against reality:</p>
<p>What we‚Äôre looking at: - Red points: observed data (actual death rates at each dose) - Blue lines: predicted dose-response curves from posterior samples - Yellow line: mean prediction across all posterior samples</p>
<p>What we want to see: - Model predictions that capture the observed data - Reasonable uncertainty bands around predictions - No systematic deviations between model and data</p>
<p>What we observe: - Model captures the dose-response trend very well - Observed data points fall within the prediction envelope - Smooth S-shaped curve characteristic of logistic regression - Appropriate uncertainty - wider where we have less data</p>
<p>Model validation: - At dose -0.86: model predicts low death probability (‚úì matches 0/5 deaths) - At dose 0.73: model predicts high death probability (‚úì matches 5/5 deaths) - Intermediate doses show reasonable predictions</p>
<p>This suggests our model is a good fit to the data and can be trusted for making predictions at new dose levels.</p>
<p>If we saw systematic deviations, we‚Äôd need to consider: - Different link functions - Non-linear dose effects - Individual animal variability (hierarchical modeling)</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="making-predictions" class="slide level2">
<h2>Making Predictions</h2>
<div class="sourceCode" id="cb20" data-code-line-numbers="1-2|4-5|7-8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href=""></a><span class="co"># Predict mortality at new doses</span></span>
<span id="cb20-2"><a href=""></a>new_doses <span class="op">=</span> np.array([<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>])</span>
<span id="cb20-3"><a href=""></a></span>
<span id="cb20-4"><a href=""></a><span class="cf">with</span> bioassay_model:</span>
<span id="cb20-5"><a href=""></a>    pm.set_data({<span class="st">'dose'</span>: new_doses})</span>
<span id="cb20-6"><a href=""></a>    posterior_pred <span class="op">=</span> pm.sample_posterior_predictive(trace)</span>
<span id="cb20-7"><a href=""></a></span>
<span id="cb20-8"><a href=""></a><span class="co"># Get prediction intervals</span></span>
<span id="cb20-9"><a href=""></a>pred_mortality <span class="op">=</span> posterior_pred.posterior_predictive[<span class="st">'deaths'</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="center">
<div style="font-size: 1.5em; margin-top: 1em;">
<p>üîÆ Full uncertainty quantification for free!</p>
</div>
</div>
<aside class="notes">
<p>One of the biggest advantages of Bayesian modeling - making predictions with uncertainty:</p>
<p>The Process: 1. Define new dose values we want predictions for 2. Use pm.set_data() to update the model with new doses (requires dose to be defined with pm.Data) 3. Sample from posterior predictive distribution 4. Get full distribution of possible outcomes</p>
<p>What we get: - Not just point predictions, but full distributions - Credible intervals for mortality rates - Probability of any specific outcome - Proper uncertainty propagation from parameter uncertainty</p>
<p>Example interpretations: - ‚ÄúAt dose -1.0, we predict 0-2 deaths out of 5 animals with 95% probability‚Äù - ‚ÄúAt dose 1.0, we predict 4-5 deaths out of 5 animals with 95% probability‚Äù - ‚ÄúThe median predicted mortality at dose 0.0 is 60%‚Äù</p>
<p>Compared to classical approaches: - Classical: point prediction ¬± standard error - Bayesian: full predictive distribution - Can answer any question: ‚ÄúWhat‚Äôs the probability that fewer than 2 animals die?‚Äù</p>
<p>This uncertainty quantification is crucial for decision-making in pharmaceutical and toxicology applications.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="common-pitfalls-solutions" class="title-slide slide level1 center">
<h1>‚ö†Ô∏è Common Pitfalls &amp; Solutions</h1>
<div class="center">
<div style="font-size: 1.8em; margin-top: 0.5em;">
<p>Avoiding the traps that catch beginners</p>
</div>
</div>
<aside class="notes">
<p>Even with modern tools like PyMC, Bayesian modeling can go wrong. Let me share the most common issues I see and how to fix them.</p>
<p>These aren‚Äôt theoretical problems - these are real issues that will happen to you as you build more complex models. Learning to recognize and fix them is crucial for successful Bayesian analysis.</p>
<p>We‚Äôll cover: - Convergence failures and how to diagnose them - Divergences and what they mean for your results - Performance issues and optimization strategies - Prior specification problems - Model checking failures</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="convergence-diagnostics" class="slide level2">
<h2>Convergence Diagnostics</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>üìà R-hat &lt; 1.01</strong><br>
<em>Chains have converged</em></p>
<p><strong>üìä ESS &gt; 400</strong><br>
<em>Enough effective samples</em></p>
</div><div class="column" style="width:50%;">
<p><strong>‚ö†Ô∏è Zero Divergences</strong><br>
<em>No numerical issues</em></p>
<p><strong>üîó Good Mixing</strong><br>
<em>Fuzzy caterpillars in traces</em></p>
</div></div>
<aside class="notes">
<p>Always check these four diagnostics before trusting your results:</p>
<p>R-hat (Potential Scale Reduction Factor): - Compares within-chain vs between-chain variance - Should be &lt; 1.01 for all parameters - &gt; 1.01 means chains haven‚Äôt converged to the same distribution - Much &gt; 1.1 is a serious problem</p>
<p>Effective Sample Size (ESS): - How many independent samples you effectively have - Accounts for autocorrelation in MCMC chains - Need ESS &gt; 400 for basic inference, &gt; 1000 is better - Low ESS means high autocorrelation (slow mixing)</p>
<p>Divergences: - Numerical instabilities during sampling - Even a few divergences can bias results - Often indicate problems with model specification or geometry - Zero divergences is the goal</p>
<p>Chain Mixing: - Visual inspection of trace plots - Should look like ‚Äúfuzzy caterpillars‚Äù - random noise around a mean - All chains should explore the same space - Patterns, trends, or stuck chains indicate problems</p>
<p>If any of these fail, don‚Äôt interpret your results! Fix the underlying issue first.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-dreaded-divergences" class="slide level2">
<h2>The Dreaded Divergences üí•</h2>
<div style="background-color: #c62828; padding: 1.5em; border-radius: 0.5em; margin-top: 2em;">
<div style="color: #ffcdd2; font-size: 1.2em; margin-bottom: 1em;">
<p>‚ÄúThere were 47 divergences after tuning‚Ä¶‚Äù</p>
</div>
<div style="color: #ffcdd2;">
<div style="font-size: 1.1em; margin-bottom: 1em;">
What this means:
</div>
<ul style="font-size: 0.9em;">
<li>
üö® NUTS sampler had numerical problems
</li>
<li>
üìä Your results may be biased
</li>
<li>
üîç Something is wrong with your model
</li>
<li>
‚ö° Don‚Äôt trust the posterior estimates
</li>
</ul>
</div>
</div>
<aside class="notes">
<p>Divergences are the most common and concerning diagnostic issue:</p>
<p>What are divergences? - NUTS uses Hamiltonian dynamics to propose moves - Divergences occur when the numerical integration becomes unstable - Usually happens in regions of high curvature or complex geometry - The sampler ‚Äúdiverges‚Äù from the true trajectory</p>
<p>Why they‚Äôre dangerous: - Biased sampling: divergences often occur in important regions of the posterior - Your posterior samples may not represent the true posterior - Credible intervals may be too narrow - Point estimates may be wrong</p>
<p>What causes divergences? - Poorly specified priors (too wide or too narrow) - Complex model geometry (funnels, multi-modality) - Highly correlated parameters - Numerical precision issues - Model misspecification</p>
<p>The good news: divergences are usually fixable with the right approach. We‚Äôll see how in the next slides.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="diagnosing-sampling-problems" class="slide level2">
<h2>Diagnosing Sampling Problems</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
üö® ‚ÄúBad Initial Energy‚Äù
</div>
<div class="sourceCode" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href=""></a><span class="co"># First: diagnose the problem</span></span>
<span id="cb21-2"><a href=""></a><span class="cf">with</span> model:</span>
<span id="cb21-3"><a href=""></a>    model.check_test_point()</span>
<span id="cb21-4"><a href=""></a>    </span>
<span id="cb21-5"><a href=""></a><span class="co"># Shows which variables have infinite log-prob</span></span>
<span id="cb21-6"><a href=""></a><span class="co"># Common fixes:</span></span>
<span id="cb21-7"><a href=""></a>pm.sample(init<span class="op">=</span><span class="st">'adapt_diag'</span>)</span>
<span id="cb21-8"><a href=""></a>pm.sample(init<span class="op">=</span><span class="st">'jitter+adapt_diag'</span>)</span>
<span id="cb21-9"><a href=""></a></span>
<span id="cb21-10"><a href=""></a><span class="co"># Or find reasonable starting point</span></span>
<span id="cb21-11"><a href=""></a><span class="cf">with</span> model:</span>
<span id="cb21-12"><a href=""></a>    start <span class="op">=</span> pm.find_MAP()  <span class="co"># Use sparingly</span></span>
<span id="cb21-13"><a href=""></a>    trace <span class="op">=</span> pm.sample(start<span class="op">=</span>start)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div><div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
‚ö° Divergence Solutions
</div>
<div class="sourceCode" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href=""></a><span class="co"># Step 1: More conservative sampling</span></span>
<span id="cb22-2"><a href=""></a>pm.sample(target_accept<span class="op">=</span><span class="fl">0.95</span>, tune<span class="op">=</span><span class="dv">2000</span>)</span>
<span id="cb22-3"><a href=""></a></span>
<span id="cb22-4"><a href=""></a><span class="co"># Step 2: Model reparameterization  </span></span>
<span id="cb22-5"><a href=""></a><span class="co"># Non-centered for hierarchical models</span></span>
<span id="cb22-6"><a href=""></a>theta_raw <span class="op">=</span> pm.Normal(<span class="st">'theta_raw'</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb22-7"><a href=""></a>theta <span class="op">=</span> pm.Deterministic(<span class="st">'theta'</span>, mu <span class="op">+</span> tau <span class="op">*</span> theta_raw)</span>
<span id="cb22-8"><a href=""></a></span>
<span id="cb22-9"><a href=""></a><span class="co"># Step 3: Check prior constraints</span></span>
<span id="cb22-10"><a href=""></a>sigma <span class="op">=</span> pm.HalfNormal(<span class="st">'sigma'</span>, <span class="dv">1</span>)  <span class="co"># not Normal</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div>
<aside class="notes">
<p>‚ÄúBad initial energy‚Äù and divergence errors are the top sampling issues beginners face:</p>
<p>‚ÄúBad Initial Energy‚Äù Diagnosis: - Cryptic error message but straightforward diagnosis process - Run model.check_test_point() to identify which variables have infinite log-probability - Usually caused by inappropriate priors (Normal for positive parameters) - Or initialization in impossible regions of parameter space</p>
<p>Practical Fixes: - init=‚Äòadapt_diag‚Äô: better initialization using diagonal mass matrix - init=‚Äòjitter+adapt_diag‚Äô: adds random jitter to starting values<br>
- pm.find_MAP(): finds mode to start from (use sparingly, discouraged for modern practice) - Check and fix prior specifications first</p>
<p>Divergence Solutions (Hierarchical): - ‚ÄúThere were X divergences after tuning‚Äù is common with hierarchical models - Knee-jerk reaction: increase target_accept (0.9 to 0.99 often helps) - Real solution: non-centered parameterization for hierarchical structures - theta_raw ~ Normal(0,1) then theta = mu + tau * theta_raw - Separates location (mu) and scale (tau) effects, easier geometry</p>
<p>Systematic Approach: 1. Check model.check_test_point() for infinite values 2. Fix prior constraints (HalfNormal for positive parameters)<br>
3. Try conservative sampling (target_accept=0.95, tune=2000) 4. Reparameterize hierarchical components if needed 5. Only then consider more advanced techniques</p>
<p>Most ‚ÄúBad initial energy‚Äù errors trace to wrong prior constraints - fix those first.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="performance-optimization" class="slide level2">
<h2>Performance Optimization</h2>
<div class="columns">
<div class="column" style="width:33%;">
<div style="text-align: center;">
<div style="font-size: 3em; margin-bottom: 0.5em;">
üöÄ
</div>
<div style="font-size: 1.2em; margin-bottom: 0.5em;">
JAX Backend
</div>
<div style="font-size: 0.9em; color: #888;">
5-10x speedup for many models
</div>
</div>
</div><div class="column" style="width:33%;">
<div style="text-align: center;">
<div style="font-size: 3em; margin-bottom: 0.5em;">
üìä
</div>
<div style="font-size: 1.2em; margin-bottom: 0.5em;">
Vectorization
</div>
<div style="font-size: 0.9em; color: #888;">
Avoid loops, use tensor operations
</div>
</div>
</div><div class="column" style="width:33%;">
<div style="text-align: center;">
<div style="font-size: 3em; margin-bottom: 0.5em;">
üéØ
</div>
<div style="font-size: 1.2em; margin-bottom: 0.5em;">
Simpler Models
</div>
<div style="font-size: 0.9em; color: #888;">
Start simple, add complexity gradually
</div>
</div>
</div></div>
<div class="sourceCode" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href=""></a><span class="co"># Switch to JAX backend for speed</span></span>
<span id="cb23-2"><a href=""></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb23-3"><a href=""></a>pm.set_backend(<span class="st">'jax'</span>)</span>
<span id="cb23-4"><a href=""></a></span>
<span id="cb23-5"><a href=""></a><span class="co"># Or install numpyro for even more speed</span></span>
<span id="cb23-6"><a href=""></a><span class="co"># pip install numpyro</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<aside class="notes">
<p>If your models are running slowly, here are the main optimization strategies:</p>
<p>JAX Backend: - Can provide 5-10x speed improvements - GPU support for very large models - JIT compilation optimizes repeated operations - Install: pip install numpyro - Switch: pm.set_backend(‚Äòjax‚Äô) - Not all PyMC features supported yet</p>
<p>Vectorization: - Avoid explicit loops in your model - Use tensor operations instead - Let PyMC/NumPy handle the broadcasting - Example: instead of for loop over observations, use vector operations</p>
<p>Model Simplification: - Start with the simplest model that could work - Add complexity only when needed - More parameters = slower sampling - Sometimes a simpler model is actually better</p>
<p>Other optimizations: - Standardize your predictors (zero mean, unit variance) - Use informative priors when possible - Consider model approximations (variational inference) - Profile your code to find bottlenecks</p>
<p>Remember: premature optimization is the root of all evil. Get your model working correctly first, then optimize if needed.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="prior-specification-problems" class="slide level2">
<h2>Prior Specification Problems</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="background-color: #c62828; padding: 1em; border-radius: 0.5em;">
<div style="color: #ffcdd2; font-weight: bold; margin-bottom: 0.5em;">
‚ùå Wrong Constraints
</div>
<div style="font-size: 0.9em; color: #ffcdd2; font-family: monospace;">
<pre><code># Allows negative values!&lt;br&gt;
sigma = pm.Normal('sigma', 0, 5)</code></pre>
</div>
<div style="font-size: 0.9em; color: #ffcdd2; margin-top: 0.5em;">
<pre><code>‚Üí "Bad initial energy" errors&lt;br&gt;
‚Üí Impossible likelihoods</code></pre>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="background-color: #2e7d32; padding: 1em; border-radius: 0.5em;">
<div style="color: #c8e6c9; font-weight: bold; margin-bottom: 0.5em;">
‚úÖ Proper Constraints
</div>
<div style="font-size: 0.9em; color: #c8e6c9; font-family: monospace;">
<pre><code># Ensures positive values&lt;br&gt;
sigma = pm.HalfNormal('sigma', 5)</code></pre>
</div>
<div style="font-size: 0.9em; color: #c8e6c9; margin-top: 0.5em;">
<pre><code>‚Üí Stable sampling&lt;br&gt;
‚Üí Reasonable constraint</code></pre>
</div>
</div>
</div></div>
<div style="background-color: #1565c0; padding: 1em; border-radius: 0.5em; margin-top: 1.5em;">
<div style="color: #bbdefb; font-weight: bold; margin-bottom: 0.5em;">
üéØ Golden Rules
</div>
<div style="font-size: 0.9em; color: #bbdefb;">
<p>‚Ä¢ <strong>Standard deviations:</strong> HalfNormal, not Normal<br> ‚Ä¢ <strong>Probabilities:</strong> Beta(2,2), not Uniform(0,1)<br> ‚Ä¢ <strong>Coefficients:</strong> Normal(0, 2.5) for standardized data<br> ‚Ä¢ <strong>Always</strong> do prior predictive checks!</p>
</div>
</div>
<aside class="notes">
<p>The classic beginner mistake: using Normal priors for parameters that must be positive:</p>
<p>Wrong Constraint Priors: - sigma = pm.Normal(‚Äòsigma‚Äô, mu=0, sigma=5) allows negative values - Creates ‚ÄúBad initial energy‚Äù errors when MCMC draws negative standard deviations<br>
- Impossible likelihoods when sigma &lt; 0 - This is the most frustrating category of errors for beginners</p>
<p>The Fix is Simple: - Use constrained distributions: HalfNormal, Exponential, Gamma for positive parameters - sigma = pm.HalfNormal(‚Äòsigma‚Äô, sigma=5) ensures sigma &gt; 0 - Critical for standard deviations, variances, rates, scales</p>
<p>Other Common Prior Mistakes: - Overly vague priors (sigma=10000) allow unrealistic parameter values - Uniform priors create sampling difficulties (flat regions are hard to explore) - Normal priors for probabilities (should use Beta)</p>
<p>Practical Rules for Common Parameters: - Standard deviations: HalfNormal(sigma=1) or Exponential(lam=1) - Probabilities: Beta(2, 2) (mild preference for 0.5) - Correlation coefficients: LKJ prior for positive definite matrices - Regression coefficients: Normal(0, 2.5) for standardized predictors</p>
<p>The pattern: choose distributions whose support matches parameter constraints. Prior predictive checks catch violations before sampling.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="debugging-workflow" class="slide level2">
<h2>Debugging Workflow</h2>
<div style="font-size: 1.5em; margin-bottom: 2em; text-align: center;">
When things go wrong‚Ä¶
</div>
<div class="columns">
<div class="column" style="width:50%;">
<div style="font-size: 1.2em; margin-bottom: 1em;">
üîç Diagnostic Steps
</div>
<ol style="font-size: 0.9em;">
<li>
Check trace plots
</li>
<li>
Look at R-hat values
</li>
<li>
Check effective sample size
</li>
<li>
Count divergences
</li>
<li>
Do posterior predictive checks
</li>
</ol>
</div><div class="column" style="width:50%;">
<div style="font-size: 1.2em; margin-bottom: 1em;">
üõ†Ô∏è Fix Strategy
</div>
<ol style="font-size: 0.9em;">
<li>
Try sampler tuning first
</li>
<li>
Examine prior predictive samples
</li>
<li>
Simplify the model
</li>
<li>
Reparameterize if needed
</li>
<li>
Ask for help on discourse!
</li>
</ol>
</div></div>
<aside class="notes">
<p>When your model isn‚Äôt working, follow this systematic debugging approach:</p>
<p>Diagnostic Phase: 1. Trace plots: Do they look like fuzzy caterpillars? 2. R-hat: Are all values &lt; 1.01? 3. ESS: Do you have &gt; 400 effective samples? 4. Divergences: Are there any? Even a few is concerning 5. Posterior predictive: Does the model capture your data?</p>
<p>Fix Strategy: 1. Sampler tuning: Try target_accept=0.95, more tuning steps 2. Prior predictive: Do your priors make sense? Generate reasonable data? 3. Simplify: Remove complexity until it works, then add back gradually 4. Reparameterize: Non-centered parameterization, parameter transforms 5. Get help: PyMC community is very supportive of beginners</p>
<p>Common Progression: - Start with simplest possible model - Check it works (good diagnostics) - Add one piece of complexity at a time - Diagnose issues immediately when they arise - Don‚Äôt move forward with bad diagnostics</p>
<p>Remember: a simple model that works is better than a complex model that doesn‚Äôt. You can always add complexity later once you have a solid foundation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="conceptual-clarifications" class="slide level2">
<h2>ü§î Conceptual Clarifications</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="background-color: #ff8f00; padding: 1em; border-radius: 0.5em;">
<div style="color: #fff3e0; font-weight: bold; margin-bottom: 0.5em;">
üó∫Ô∏è find_MAP() Deprecation
</div>
<div style="font-size: 0.9em; color: #fff3e0;">
<pre><code>&lt;strong&gt;Old tutorials say:&lt;/strong&gt; Start with MAP&lt;br&gt;
&lt;strong&gt;Modern practice:&lt;/strong&gt; Just call pm.sample()&lt;br&gt;
&lt;strong&gt;Why?&lt;/strong&gt; MAP isn't representative in high dimensions</code></pre>
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="background-color: #1565c0; padding: 1em; border-radius: 0.5em;">
<div style="color: #bbdefb; font-weight: bold; margin-bottom: 0.5em;">
üî¢ PyMC3 vs PyMC
</div>
<div style="font-size: 0.9em; color: #bbdefb;">
<pre><code>&lt;strong&gt;PyMC3:&lt;/strong&gt; Old name (legacy)&lt;br&gt;
&lt;strong&gt;PyMC:&lt;/strong&gt; Current name (v4+)&lt;br&gt;
&lt;strong&gt;Migration:&lt;/strong&gt; Most code works with minor changes</code></pre>
</div>
</div>
</div></div>
<div style="background-color: #2e7d32; padding: 1em; border-radius: 0.5em; margin-top: 1.5em;">
<div style="color: #c8e6c9; font-weight: bold; margin-bottom: 0.5em;">
üìä Prior vs Posterior Predictive
</div>
<div style="font-size: 0.9em; color: #c8e6c9;">
<p><strong>Prior predictive:</strong> Validate model assumptions <em>before</em> seeing data<br> <strong>Posterior predictive:</strong> Compare model predictions <em>after</em> fitting<br> <strong>Key:</strong> Use joint distributions, not marginals (parameters are correlated!)</p>
</div>
</div>
<aside class="notes">
<p>Conceptual confusions that persist even after technical issues are resolved:</p>
<p>find_MAP() Deprecation Confusion: - Older tutorials and books recommend starting with MAP estimates - find_MAP() was deprecated because MAP estimates aren‚Äôt representative in high dimensions - Modern practice: just call pm.sample() directly with good initialization strategies - NUTS is robust enough to find good starting points automatically - MAP can actually hinder NUTS sampling by starting in atypical regions</p>
<p>Version Confusion (PyMC3 vs PyMC): - PyMC3 was renamed to PyMC starting with version 4 - Current PyMC (v5+) is the actively developed version - Most PyMC3 code works with minor modifications - Don‚Äôt panic if you see ‚ÄúPyMC3‚Äù in old tutorials - concepts translate directly - Check import statements: import pymc3 -&gt; import pymc as pm</p>
<p>Prior vs Posterior Predictive Confusion: - Prior predictive: sample from model before seeing data, validates assumptions - Posterior predictive: sample from fitted model, compares to observed data<br>
- Both require joint distributions because parameters are typically correlated - Common mistake: using marginal distributions instead of joint samples - Prior predictive catches model specification errors early - Posterior predictive validates model fit to actual data</p>
<p>These conceptual issues cause anxiety but are easily resolved with modern workflows.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="pymc-ecosystem" class="title-slide slide level1 center">
<h1>üåü PyMC Ecosystem</h1>
<div class="center">
<div style="font-size: 1.8em; margin-top: 0.5em;">
<p>Beyond core PyMC: tools that extend your capabilities</p>
</div>
</div>
</section>
<section id="arviz-your-visualization-partner" class="slide level2">
<h2>ArviZ: Your Visualization Partner</h2>
<div class="columns">
<div class="column" style="width:33%;">
<div style="text-align: center;">
<div style="font-size: 3em; margin-bottom: 0.5em;">
üìä
</div>
<div style="font-size: 1.2em; margin-bottom: 0.5em;">
Trace Plots
</div>
<div style="font-size: 0.9em;">
Check convergence
</div>
</div>
</div><div class="column" style="width:33%;">
<div style="text-align: center;">
<div style="font-size: 3em; margin-bottom: 0.5em;">
üé®
</div>
<div style="font-size: 1.2em; margin-bottom: 0.5em;">
Forest Plots
</div>
<div style="font-size: 0.9em;">
Compare parameters
</div>
</div>
</div><div class="column" style="width:33%;">
<div style="text-align: center;">
<div style="font-size: 3em; margin-bottom: 0.5em;">
üîç
</div>
<div style="font-size: 1.2em; margin-bottom: 0.5em;">
Model Checking
</div>
<div style="font-size: 0.9em;">
Validate assumptions
</div>
</div>
</div></div>

<img data-src="./public/plots/bioassay/forest_plot.png" class="quarto-figure quarto-figure-center r-stretch"><aside class="notes">
<p>ArviZ is the standard tool for Bayesian visualization and diagnostics:</p>
<p>Key Plot Types:</p>
<p>Trace Plots: - Monitor MCMC convergence - Identify mixing problems - Essential for any Bayesian analysis</p>
<p>Forest Plots: - Compare parameter estimates across models - Show credible intervals clearly - Great for hierarchical models with many parameters</p>
<p>Posterior Plots: - Visualize parameter distributions - Show credible intervals and point estimates - Easy to interpret and share</p>
<p>Model Checking: - Posterior predictive checks - LOO-CV for model comparison - Energy plots for NUTS diagnostics - Rank plots for convergence assessment</p>
<p>Why ArviZ? - Publication-quality plots out of the box - Consistent API across different samplers (PyMC, Stan, etc.) - Extensive customization options - Integrates seamlessly with PyMC - Active development and great documentation</p>
<p>The forest plot shown illustrates parameter estimates with uncertainty - much more informative than traditional point estimates + error bars.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="bambi-high-level-modeling" class="slide level2">
<h2>Bambi: High-Level Modeling</h2>
<div class="sourceCode" id="cb30" data-code-line-numbers="1-2|4-5|7-8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href=""></a><span class="im">import</span> bambi <span class="im">as</span> bmb</span>
<span id="cb30-2"><a href=""></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb30-3"><a href=""></a></span>
<span id="cb30-4"><a href=""></a><span class="co"># R-style formula interface</span></span>
<span id="cb30-5"><a href=""></a>model <span class="op">=</span> bmb.Model(<span class="st">'y ~ x1 + x2 + (1|group)'</span>, data<span class="op">=</span>df)</span>
<span id="cb30-6"><a href=""></a></span>
<span id="cb30-7"><a href=""></a><span class="co"># Automatic priors and sampling</span></span>
<span id="cb30-8"><a href=""></a>results <span class="op">=</span> model.fit()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="center">
<div style="font-size: 1.5em; margin-top: 1em;">
<p>üéØ Like rstanarm/brms for Python!</p>
</div>
</div>
<aside class="notes">
<p>Bambi provides a high-level interface for common statistical models:</p>
<p>Key Features:</p>
<p>Formula Interface: - R-style formula syntax: ‚Äòy ~ x1 + x2 + (1|group)‚Äô - Automatic handling of categorical variables - Built-in interactions and transformations - Hierarchical/mixed effects models</p>
<p>Automatic Priors: - Sensible default priors based on data - Weakly informative, properly scaled - Can override when needed - Handles centering and scaling automatically</p>
<p>Common Model Types: - Linear regression - Logistic regression - Hierarchical/mixed effects models - Generalized linear models - Time series models</p>
<p>When to Use Bambi: - Standard statistical models - Quick exploratory analysis - When you want to focus on interpretation, not model specification - Teaching statistics (great for students coming from R)</p>
<p>When to Use PyMC Directly: - Custom models not covered by Bambi - Need full control over priors and likelihood - Complex, domain-specific models - Research applications</p>
<p>Bambi is perfect for 80% of applied statistical modeling, while PyMC handles the remaining 20% of specialized applications.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="pymc-experimental-cutting-edge" class="slide level2">
<h2>PyMC-Experimental: Cutting Edge</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
üß™ New Methods
</div>
<ul style="font-size: 1.1em;">
<li>
Variational inference
</li>
<li>
Gaussian processes
</li>
<li>
State space models
</li>
<li>
Causal inference
</li>
</ul>
</div><div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
üöÄ Experimental Features
</div>
<ul style="font-size: 1.1em;">
<li>
New samplers
</li>
<li>
Advanced diagnostics
</li>
<li>
Model comparison
</li>
<li>
Optimization tools
</li>
</ul>
</div></div>
<div class="center">
<div style="font-size: 1.1em; color: #888; margin-top: 2em;">
<p>üí° Features graduate to main PyMC when stable</p>
</div>
</div>
<aside class="notes">
<p>PyMC-experimental is where new features are developed and tested:</p>
<p>New Statistical Methods: - Variational inference: faster approximate inference - Gaussian processes: flexible non-parametric models - State space models: time series with latent states - Causal inference: experimental designs and effect estimation</p>
<p>Experimental Features: - New MCMC samplers (beyond NUTS) - Advanced diagnostics and model checking - Information criteria and model comparison tools - Optimization algorithms for MAP estimation</p>
<p>How It Works: - Install: pip install pymc-experimental - Import specific modules you need - Features are less stable than main PyMC - Extensive testing before moving to core PyMC - Breaking changes possible between versions</p>
<p>Benefits: - Access to cutting-edge methods - Contribute to development through testing - Preview future PyMC features - Research applications requiring newest methods</p>
<p>Caution: - Less documentation than main PyMC - APIs may change - Use main PyMC for production applications - Good for research and experimentation</p>
<p>This is where the future of PyMC is being built!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="community-learning-resources" class="slide level2">
<h2>Community &amp; Learning Resources</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
üìö Learning
</div>
<ul style="font-size: 1.1em;">
<li>
üìñ <strong>pymc.io/learn</strong>
</li>
<li>
üé• YouTube tutorials
</li>
<li>
üìì Example gallery
</li>
<li>
üìö ‚ÄúBayesian Analysis with Python‚Äù
</li>
</ul>
</div><div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em;">
üí¨ Community
</div>
<ul style="font-size: 1.1em;">
<li>
üó£Ô∏è <strong>discourse.pymc.io</strong>
</li>
<li>
üê¶ <span class="citation" data-cites="pymc_devs">@pymc_devs</span>
</li>
<li>
üíª GitHub discussions
</li>
<li>
üé™ PyData conferences
</li>
</ul>
</div></div>
<div class="center">
<div style="font-size: 1.5em; color: #4FC3F7; margin-top: 2em;">
<p>ü§ù Welcoming community for all skill levels!</p>
</div>
</div>
<aside class="notes">
<p>The PyMC community is one of its greatest strengths:</p>
<p>Learning Resources:</p>
<p>Official Documentation: - pymc.io/learn: comprehensive tutorials and guides - API reference with examples - Getting started guides for different backgrounds</p>
<p>Video Content: - PyMC YouTube channel with tutorials - Conference talks from PyData events - Live coding sessions and workshops</p>
<p>Example Gallery: - 100+ worked examples covering many domains - Real datasets and complete workflows - Best practices demonstrated - Code you can copy and modify</p>
<p>Books: - ‚ÄúBayesian Analysis with Python‚Äù by Osvaldo Martin - ‚ÄúBayesian Methods for Machine Learning‚Äù by various authors - Academic textbooks using PyMC</p>
<p>Community Support:</p>
<p>Discourse Forum (discourse.pymc.io): - Primary place for questions and discussion - Searchable archive of solved problems - Core developers actively participate - Beginner-friendly atmosphere</p>
<p>Social Media: - <span class="citation" data-cites="pymc_devs">@pymc_devs</span> on Twitter for updates - LinkedIn PyMC community - Reddit r/BayesianStatistics</p>
<p>The community motto: ‚ÄúNo question is too basic!‚Äù Everyone was a beginner once.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="getting-help-contributing" class="slide level2">
<h2>Getting Help &amp; Contributing</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="background-color: #1565c0; padding: 1.5em; border-radius: 0.5em;">
<div style="color: #bbdefb; font-size: 1.2em; margin-bottom: 1em;">
üÜò Need Help?
</div>
<ul style="color: #bbdefb; font-size: 0.9em;">
<li>
‚úÖ Search discourse.pymc.io first
</li>
<li>
‚úÖ Include minimal working example
</li>
<li>
‚úÖ Share error messages and diagnostics
</li>
<li>
‚úÖ Describe what you‚Äôve tried
</li>
</ul>
</div>
</div><div class="column" style="width:50%;">
<div style="background-color: #2e7d32; padding: 1.5em; border-radius: 0.5em;">
<div style="color: #c8e6c9; font-size: 1.2em; margin-bottom: 1em;">
ü§ù Want to Contribute?
</div>
<ul style="color: #c8e6c9; font-size: 0.9em;">
<li>
üìù Documentation improvements
</li>
<li>
üêõ Bug reports with examples
</li>
<li>
üí° Feature suggestions
</li>
<li>
üß™ Testing experimental features
</li>
</ul>
</div>
</div></div>
<aside class="notes">
<p>How to get help effectively:</p>
<p>Before Asking: - Search discourse.pymc.io - your question may already be answered - Check the documentation and examples - Try to create a minimal working example</p>
<p>When Asking for Help: - Include a complete, runnable code example - Share the full error message (not just ‚Äúit doesn‚Äôt work‚Äù) - Include your PyMC and Python versions - Describe what you expected vs what happened - Show diagnostic plots if relevant</p>
<p>Good Question Example:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href=""></a><span class="im">import</span> pymc <span class="im">as</span> pm</span>
<span id="cb31-2"><a href=""></a><span class="co"># minimal data and model code</span></span>
<span id="cb31-3"><a href=""></a><span class="co"># error message</span></span>
<span id="cb31-4"><a href=""></a><span class="co"># "I expected X but got Y"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Ways to Contribute:</p>
<p>Documentation: - Fix typos and unclear explanations - Add examples for under-documented features - Improve tutorials for beginners - Translate documentation</p>
<p>Bug Reports: - Include minimal reproducing examples - Check if already reported on GitHub - Help developers understand the issue</p>
<p>Feature Requests: - Describe the use case clearly - Check if similar functionality exists - Be willing to help test implementations</p>
<p>Testing: - Try experimental features and report issues - Validate examples on different platforms - Help with pre-release testing</p>
<p>Every contribution, no matter how small, is valued by the community!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="future-directions" class="title-slide slide level1 center">
<h1>üöÄ Future Directions</h1>
<div class="center">
<div style="font-size: 1.8em; margin-top: 0.5em;">
<p>Where PyMC is heading</p>
</div>
</div>
<aside class="notes">
<p>Let‚Äôs look at where PyMC and Bayesian modeling are heading in the next few years.</p>
<p>The field is evolving rapidly, with new developments in: - Integration with AI/ML workflows - Computational performance improvements - New statistical methods and applications - Easier interfaces for domain experts</p>
<p>Understanding these trends will help you stay current and make good decisions about when and how to adopt new tools.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ai-integration" class="slide level2">
<h2>ü§ñ AI Integration</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="text-align: center;">
<div style="font-size: 4em; margin-bottom: 1em;">
üß†
</div>
<div style="font-size: 1.5em;">
LLM-Assisted Modeling
</div>
<div style="font-size: 1.1em; margin-top: 0.5em; color: #888;">
Natural language ‚Üí PyMC code
</div>
</div>
</div><div class="column" style="width:50%;">
<div style="text-align: center;">
<div style="font-size: 4em; margin-bottom: 1em;">
‚ö°
</div>
<div style="font-size: 1.5em;">
Neural Approximations
</div>
<div style="font-size: 1.1em; margin-top: 0.5em; color: #888;">
Faster inference with neural networks
</div>
</div>
</div></div>
<div class="center">
<div style="font-size: 1.1em; color: #888; margin-top: 2em;">
<p>‚ÄúBuild a hierarchical model for customer churn prediction‚Äù</p>
</div>
</div>
<aside class="notes">
<p>AI is transforming how we build and use Bayesian models:</p>
<p>LLM-Assisted Modeling: - Natural language descriptions ‚Üí PyMC code - Automatic model specification from data descriptions - Interactive debugging and model improvement - Democratizing Bayesian modeling for domain experts</p>
<p>Example workflow: User: ‚ÄúI have sales data by region and want to account for seasonal effects‚Äù AI: Generates hierarchical model with seasonal components in PyMC</p>
<p>Neural Approximations: - Neural networks to approximate posterior distributions - Much faster than MCMC for some problems - Normalizing flows for complex posterior shapes - Variational autoencoders for model comparison</p>
<p>Current Reality: - Early stage but rapidly developing - Some tools already available (GitHub Copilot helps with PyMC code) - Integration with ChatGPT/Claude for model consultation - Research active in neural posterior estimation</p>
<p>Future Vision: - Conversational model building - Automatic model criticism and improvement - AI-assisted prior elicitation - Seamless integration of domain knowledge</p>
<p>This could make Bayesian modeling accessible to many more scientists and analysts who understand their domain but not the technical details of MCMC.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="performance-revolution" class="slide level2">
<h2>‚ö° Performance Revolution</h2>
<div class="columns">
<div class="column" style="width:33%;">
<div style="text-align: center;">
<div style="font-size: 3em; margin-bottom: 0.5em;">
üöÄ
</div>
<div style="font-size: 1.2em; margin-bottom: 0.5em;">
JAX Backend
</div>
<div style="font-size: 0.9em; color: #888;">
GPU acceleration
</div>
</div>
</div><div class="column" style="width:33%;">
<div style="text-align: center;">
<div style="font-size: 3em; margin-bottom: 0.5em;">
üî•
</div>
<div style="font-size: 1.2em; margin-bottom: 0.5em;">
Compilation
</div>
<div style="font-size: 0.9em; color: #888;">
JIT optimization
</div>
</div>
</div><div class="column" style="width:33%;">
<div style="text-align: center;">
<div style="font-size: 3em; margin-bottom: 0.5em;">
üìà
</div>
<div style="font-size: 1.2em; margin-bottom: 0.5em;">
Scalability
</div>
<div style="font-size: 0.9em; color: #888;">
Larger datasets
</div>
</div>
</div></div>
<div class="center">
<div style="font-size: 1.5em; margin-top: 2em;">
<p>100x speedups possible for large models</p>
</div>
</div>
<aside class="notes">
<p>Performance improvements are making Bayesian modeling feasible for much larger problems:</p>
<p>JAX Backend: - GPU/TPU acceleration for massive models - Automatic differentiation optimized for modern hardware - Vectorized operations across multiple devices - Already 5-10x faster for many models</p>
<p>JIT Compilation: - XLA compiler optimizes entire model graphs - Eliminates Python overhead - Aggressive optimization for repeated operations - Cold start penalty but then much faster</p>
<p>Scalability Improvements: - Handle millions of observations - Thousands of parameters in hierarchical models - Real-time inference for streaming data - Distributed computation across clusters</p>
<p>Current Status: - JAX backend already available and improving - Some limitations vs NumPy backend - Research into specialized hardware (TPUs) - Integration with cloud computing platforms</p>
<p>Impact: - Previously impossible models now feasible - Real-time decision making with Bayesian uncertainty - Large-scale A/B testing and experimentation - Industrial applications with big data</p>
<p>This performance revolution is making Bayesian methods competitive with classical ML for large-scale applications.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="growing-applications" class="slide level2">
<h2>üåç Growing Applications</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em; color: #9C27B0;">
üî¨ Science
</div>
<ul style="font-size: 0.9em;">
<li>
Climate modeling
</li>
<li>
Genomics &amp; personalized medicine
</li>
<li>
Astronomy &amp; cosmology
</li>
<li>
Social sciences
</li>
</ul>
</div><div class="column" style="width:50%;">
<div style="font-size: 1.5em; margin-bottom: 1em; color: #2196F3;">
üè¢ Industry
</div>
<ul style="font-size: 0.9em;">
<li>
Supply chain optimization
</li>
<li>
Financial risk modeling
</li>
<li>
Marketing mix modeling
</li>
<li>
Quality control
</li>
</ul>
</div></div>
<div class="center">
<div style="font-size: 1.1em; color: #888; margin-top: 2em;">
<p>Uncertainty quantification becoming essential everywhere</p>
</div>
</div>
<aside class="notes">
<p>Bayesian methods are expanding into new domains:</p>
<p>Scientific Applications: - Climate modeling: quantifying uncertainty in climate projections - Genomics: personalized medicine with individual-level predictions - Astronomy: discovering exoplanets and dark matter - Social sciences: causal inference and policy evaluation</p>
<p>Industrial Applications: - Supply chain: robust optimization under uncertainty - Finance: regulatory compliance requires uncertainty quantification - Marketing: attribution and media mix optimization - Manufacturing: quality control and predictive maintenance</p>
<p>Why the Growth? - Regulatory requirements for uncertainty quantification - AI safety concerns driving need for calibrated confidence - Better tools making Bayesian methods more accessible - Recognition that point estimates are insufficient</p>
<p>Market Trends: - Consulting firms building Bayesian practices - Software companies integrating uncertainty quantification - Academic programs emphasizing Bayesian statistics - Industry standards requiring probabilistic forecasts</p>
<p>The future is probabilistic - organizations that embrace uncertainty quantification will have competitive advantages in decision-making under uncertainty.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="how-you-can-contribute" class="slide level2">
<h2>ü§ù How You Can Contribute</h2>
<div class="columns">
<div class="column" style="width:50%;">
<div style="background-color: #1565c0; padding: 1.5em; border-radius: 0.5em;">
<div style="color: #bbdefb; font-size: 1.2em; margin-bottom: 1em;">
üë©‚Äçüíª Technical
</div>
<ul style="color: #bbdefb; font-size: 0.9em;">
<li>
üêõ Report bugs with examples
</li>
<li>
üìö Improve documentation
</li>
<li>
üß™ Test experimental features
</li>
<li>
üí° Contribute code improvements
</li>
</ul>
</div>
</div><div class="column" style="width:50%;">
<div style="background-color: #2e7d32; padding: 1.5em; border-radius: 0.5em;">
<div style="color: #c8e6c9; font-size: 1.2em; margin-bottom: 1em;">
üåü Community
</div>
<ul style="color: #c8e6c9; font-size: 0.9em;">
<li>
‚ùì Answer questions on discourse
</li>
<li>
‚úçÔ∏è Write tutorials and blog posts
</li>
<li>
üé§ Give talks at meetups
</li>
<li>
üë• Organize local user groups
</li>
</ul>
</div>
</div></div>
<div class="center">
<div style="font-size: 1.5em; color: #FF9800; margin-top: 2em;">
<p>üöÄ Join us in building the future of data science!</p>
</div>
</div>
<aside class="notes">
<p>The PyMC community thrives on contributions from users like you:</p>
<p>Technical Contributions:</p>
<p>Bug Reports: - Include minimal reproducing examples - Help developers understand and fix issues - Make PyMC more reliable for everyone</p>
<p>Documentation: - Fix typos and unclear explanations - Add examples for complex features - Improve tutorials for beginners - Translate content to other languages</p>
<p>Testing: - Try new features before release - Report compatibility issues - Help with cross-platform testing</p>
<p>Code: - Fix bugs in your area of expertise - Implement new features - Optimize performance - Add new distributions or samplers</p>
<p>Community Contributions:</p>
<p>Support: - Answer questions on discourse.pymc.io - Help newcomers get started - Share your expertise</p>
<p>Content Creation: - Write blog posts about your analyses - Create video tutorials - Share case studies from your domain - Publish reproducible research</p>
<p>Outreach: - Give talks at conferences and meetups - Organize workshops at your institution - Start local PyMC user groups - Advocate for Bayesian methods in your field</p>
<p>Every contribution matters - the community values all forms of participation!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section id="questions" class="title-slide slide level1 center">
<h1>Questions? ü§î</h1>
<div class="center">
<div style="font-size: 1.5em; margin-top: 2em; margin-bottom: 3em;">
<p>Thank you for joining this PyMC journey!</p>
</div>
</div>
<div class="columns">
<div class="column" style="width:33%;">
<div class="center">
<div style="font-size: 2em; margin-bottom: 0.5em;">
üí¨
</div>
<div>
discourse.pymc.io
</div>
</div>
</div><div class="column" style="width:33%;">
<div class="center">
<div style="font-size: 2em; margin-bottom: 0.5em;">
üìö
</div>
<div>
pymc.io
</div>
</div>
</div><div class="column" style="width:33%;">
<div class="center">
<div style="font-size: 2em; margin-bottom: 0.5em;">
ü¶ã
</div>
<div>
<span class="citation" data-cites="pymc.io">@pymc.io</span>
</div>
</div>
</div></div>
<div class="center">
<div style="color: #888; margin-top: 2em;">
<p>Slides: github.com/fonnesbeck/du_pymc_tutorial</p>
</div>
</div>
<aside class="notes">
<p>Thank you for joining this comprehensive introduction to PyMC!</p>
<p>Quick recap of what we covered: - What PyMC is and why Bayesian modeling matters - Installation and setup (easier than you might think!) - Core concepts: models, distributions, observed data - Complete worked example with real data and diagnostics - Common pitfalls and how to avoid them - The broader ecosystem and community resources - Future directions and opportunities to contribute</p>
<p>Key takeaways: 1. Bayesian modeling gives you uncertainty quantification for free 2. PyMC makes complex statistical modeling accessible 3. Always check your diagnostics before trusting results 4. The community is welcoming and supportive 5. Start simple and add complexity gradually</p>
<p>Next steps: - Try the bioassay example yourself - Apply PyMC to your own data - Join the discourse forum for support - Explore the example gallery for inspiration</p>
<p>Resources for continued learning: - discourse.pymc.io: get help and see discussions - pymc.io: official documentation and tutorials - <span class="citation" data-cites="pymc_devs">@pymc_devs</span>: stay updated on new developments</p>
<p>Remember: every expert was once a beginner. Don‚Äôt hesitate to ask questions and engage with the community!</p>
<p>Happy Bayesian modeling! üéâ</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>

</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="slides_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="slides_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="slides_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="slides_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="slides_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="slides_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="slides_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="slides_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="slides_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: true,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1600,

        height: 900,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        // Bounds for smallest/largest possible scale to apply to content
        minScale: 0.2,

        maxScale: 2,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>